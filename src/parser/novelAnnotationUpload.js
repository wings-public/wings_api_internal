#!/usr/bin/env node
'use strict';

const fs = require('fs');
const path = require('path');
const zlib = require('zlib');
const readline = require('readline');
const argParser = require('commander');
const colors = require('colors');

const { createLogger, format, transports } = require('winston');
const configData = require('../config/config.js');
const { db : {dbName,variantAnnoCollection1,variantAnnoCollection2}, app:{instance} } = configData;

var createConnection = require('../controllers/dbConn.js').createConnection;
const getConnection = require('../controllers/dbConn.js').getConnection;
var initialize = require('../controllers/entityController.js').initialize;
var loggerMod = require('../controllers/loggerMod');

var bson = require("bson");
var BSON = new bson.BSON();
var client;

(async function () {
    argParser
        .version('0.1.0')
        .option('-p, --parser <Novel>', 'Annotation Source')
        .option('-i, --input_file <file1>', 'json.gz novel Annotations file generated by parser')
        .option('--assembly, --assembly <GRCh37,GRCh38>', 'assembly type to decide the import collection to be used for import')
    argParser.parse(process.argv);


    if ((!argParser.parser) || (!argParser.input_file) || (!argParser.assembly)) {
        argParser.outputHelp(applyFont);
        process.exit(1);
    }
    
    var inputFile = argParser.input_file;
    var assemblyType = argParser.assembly;
    ///////////////////// Winston Logger //////////////////////////////
    var logFile = 'novelAnnoUpload-'+process.pid+'.log';
    //const filename = path.join(logDir, 'results.log');
    //var filename;

    // To be added to a separate library //////
    /*if ( instance == 'dev') {
        // Create the log directory if it does not exist
        const logDir = 'log';
        if (!fs.existsSync(logDir)) {
            fs.mkdirSync(logDir);
        }
        filename = path.join(logDir, logFile);
    } else {
        // env ( uat, prod ) will be using docker instance. Logs has to be created in the corresponding bind volumes defined in the docker-compose environment file
        // importLogPath will be defined in docker-compose environment variables section 
        filename = path.join(process.env.importLogPath, logFile);
    }*/

    var createLog = loggerMod.logger('tmp',logFile);
    //var createLog = loggerMod.logger(filename);
    
    /////////////////////// Winston Logger ///////////////////////////// 
    try {
        await createConnection();
        createLog.debug("Calling initialize to create the initial collections");
        var data = await initialize();
    } catch(e) {
        createLog.debug("Error is "+e);
    }


    client = getConnection();
    const db = client.db(dbName);
    //createLog.debug("VariantAnnoCollection is "+variantAnnoCollection);
    var variantAnnoCollection;
    if ( assemblyType == "GRCh37") {
        variantAnnoCollection = variantAnnoCollection1;
    } else if ( assemblyType == "GRCh38" ) {
        variantAnnoCollection = variantAnnoCollection2;
    } 
    var annoCollection = db.collection(variantAnnoCollection);

    //// Validate VCF File, ID and also ID for Multi-Sample VCF Files ///
    try {
        var val = await parseFile(inputFile,createLog,annoCollection);
        createLog.debug("Check the value returned from the promise of parseFile");
        if ( ( val == "Success" ) || ( val == "Duplicate" ) ) {
            createLog.debug("Hey !! exit the process ");
            process.exit(0);
        }
    } catch(err) {
        createLog.debug("Error is "+err);
        process.exit(0);
    }

})();

async function parseFile(file,createLog,annoCollection) {
    var reFile = /\.gz/g;
    var rd;
    if (file.match(reFile)) {
        rd = readline.createInterface({
            input: fs.createReadStream(file).pipe(zlib.createGunzip()),
            console: false
        });
    } else {
        rd = readline.createInterface({
            input: fs.createReadStream(file),
            console: false
        });
    }

    var basePath = path.parse(__dirname).dir;
    var jsonP = path.join(basePath,'config','chrMap.json');

    var mapJson = fs.readFileSync(jsonP);
    var chrData = JSON.parse(mapJson);
    var chrMap = chrData['chromosomes'];

    var bulkOps = [];
    rd.on('line', function (line) {
        var document = {};
        var updateDoc = {};
        var parsedJson = JSON.parse(line);
        //console.dir(parsedJson);

        var filter = {};
        var setFilter = {};
        var updateFilter = {};

        var id = parsedJson['_id'];
        var arr = id.split('-');

        // Chromosome number for X and Y were replaced to numerical counterparts when novel variants were generated
        // Reason : Annotation ENgines VEP,CADD expects the chromosomes X and Y. Update them before uploading the annotations to mongo collections
        if ( arr[0] == "X" ) {
            var chr = 23;
            id = chr+'-'+arr[1]+'-'+arr[2]+'-'+arr[3];
        } else if ( arr[0] == "Y" ) {
            var chr = 24;
            id = chr+'-'+arr[1]+'-'+arr[2]+'-'+arr[3];
        } else {
            // update chromosome as part of id for non-canonical chromosomes
            //var mapChr1 = 'chr'+arr[0];
            var mapChr1 = arr[0];
            //console.log(`mapChr1 ${mapChr1}`);
            if ( chrMap[mapChr1] ) {
                var intChr = chrMap[mapChr1];
                //console.log(`intChr ${intChr}`);
                id = intChr+'-'+arr[1]+'-'+arr[2]+'-'+arr[3];
                //console.log(`id ${id}`);
            }
        }

        // Check and retrieve the data from the structures that were exported by the parser engine from mongodb
        // structure match with the existing data structure. retrieve the data and upload them to the mongo annotation collection
        if ( parsedJson['ClinVar'] ) {
            setFilter['ClinVar'] = parsedJson['ClinVar'];
        }

        if ( parsedJson['annotation'] ) {
            setFilter['annotation'] = parsedJson['annotation'];
        }
 
        if ( parsedJson['gnomAD'] ) {
            setFilter['gnomAD'] = parsedJson['gnomAD'];
        }

        if ( parsedJson['CADD_PhredScore'] ) {
            setFilter['CADD_PhredScore'] = parsedJson['CADD_PhredScore'];
        }
        
        setFilter['annotated'] = 1;
        filter['filter'] = {'_id' : id};
        filter['update'] = {$set : setFilter};

        updateFilter['updateOne'] = filter;
        // by default upsert is false. Setting it to true below
        updateFilter['updateOne']['upsert'] = 1;
        
        bulkOps.push(updateFilter);
        if ( bulkOps.length  === 1000 ) {
            createLog.debug("Execute the bulk update ");
            //console.dir(bulkOps,{"depth":null});
            annoCollection.bulkWrite(bulkOps, { 'ordered': false }).then(function (res) {
                createLog.debug(res.insertedCount, res.modifiedCount, res.deletedCount);
            }).catch((err1) => {
                createLog.debug("Error executing the bulk operations");
                createLog.debug(err1);
            });
            createLog.debug("Initializing bulkOps to 0");
            bulkOps = [];
        }
    });

    return new Promise( resolve => {
        rd.on('close', async () => {
            if ( bulkOps.length > 0 ) {
                try {
                    var res1 = await annoCollection.bulkWrite(bulkOps,{'ordered':false});
                    resolve("Success");
                } catch(err1) {
                    // duplicate key issue when the key is present in the existing mongo collection
                    resolve("Duplicate");
                }
            } else {
                // This condition is required to handle the case when the size of bulkOps data was loaded in the previous modulus 
                // When there is not enough data to be loaded to mongo db, we have to resolve the promise to ensure that it is resolved at the calling await
                // exit condition of the process is performed on the resolved promise
                resolve("Success");
            }
        });
    });

    rd.on('end', function () {
        createLog.debug("END event call received");
    });

    rd.on('error', function () {
        createLog.debug("ERROR event call received.Filehandle destroyed. Internal!!");
    });
}

function applyFont(txt) {
    return colors.red(txt); //display the help text in red on the console
}


