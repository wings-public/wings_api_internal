#!/usr/bin/env node
'use strict';

const fs = require('fs');
const path = require('path');
const zlib = require('zlib');
const readline = require('readline');
const argParser = require('commander');
const colors = require('colors');

const { createLogger, format, transports } = require('winston');
const configData = require('../config/config.js');
const { db : {dbName,variantAnnoCollection1,variantAnnoCollection2}, app:{instance} } = configData;

var createConnection = require('../controllers/dbConn.js').createConnection;
const getConnection = require('../controllers/dbConn.js').getConnection;
var initialize = require('../controllers/entityController.js').initialize;
var loggerMod = require('../controllers/loggerMod');

var bson = require("bson");
var BSON = new bson.BSON();
var client;

(async function () {
    argParser
        .version('0.1.0')
        .option('-p, --parser <Novel>', 'Annotation Source')
        .option('-i, --input_file <file1>', 'json.gz novel Annotations file generated by parser')
        .option('--assembly, --assembly <GRCh37,GRCh38>', 'assembly type to decide the import collection to be used for import')
        .option('--type, --type <reannotate>', 'type which indicates if the request is to reannotate variants')
    argParser.parse(process.argv);


    if ((!argParser.parser) || (!argParser.input_file) || (!argParser.assembly)) {
        argParser.outputHelp(applyFont);
        process.exit(1);
    }
    
    var inputFile = argParser.input_file;
    var assemblyType = argParser.assembly;
    ///////////////////// Winston Logger //////////////////////////////
    var logFile = 'novelAnnoUpload-'+process.pid+'.log';
    //const filename = path.join(logDir, 'results.log');
    //var filename;

    // To be added to a separate library //////
    /*if ( instance == 'dev') {
        // Create the log directory if it does not exist
        const logDir = 'log';
        if (!fs.existsSync(logDir)) {
            fs.mkdirSync(logDir);
        }
        filename = path.join(logDir, logFile);
    } else {
        // env ( uat, prod ) will be using docker instance. Logs has to be created in the corresponding bind volumes defined in the docker-compose environment file
        // importLogPath will be defined in docker-compose environment variables section 
        filename = path.join(process.env.importLogPath, logFile);
    }*/

    var createLog = loggerMod.logger('tmp',logFile);
    //var createLog = loggerMod.logger(filename);
    
    /////////////////////// Winston Logger ///////////////////////////// 
    try {
        await createConnection();
        createLog.debug("Calling initialize to create the initial collections");
        var data = await initialize();
    } catch(e) {
        createLog.debug("Error is "+e);
    }


    client = getConnection();
    const db = client.db(dbName);
    //createLog.debug("VariantAnnoCollection is "+variantAnnoCollection);
    var variantAnnoCollection;
    var archiveAnnoColl;

    // Versioned anno : archived annotation collection to be used for getting novel variants
    var verAnnoColl1;var verAnnoColl2;var annoVer;
    try {
        if ( process.env.HIST_ANNO_VER ) {
            console.log("History Anno versioning true");
            annoVer = process.env.HIST_ANNO_VER;
            verAnnoColl1 = variantAnnoCollection1+annoVer;
            verAnnoColl2 = variantAnnoCollection2+annoVer;
        }
    } catch(err) {
        console.log(err);
    }


    if ( assemblyType == "GRCh37") {
        variantAnnoCollection = variantAnnoCollection1;
        archiveAnnoColl = verAnnoColl1;
    } else if ( assemblyType == "GRCh38" ) {
        variantAnnoCollection = variantAnnoCollection2;
        archiveAnnoColl = verAnnoColl2;
    } 
    var annoCollection = db.collection(variantAnnoCollection);
    var archiveAnnoCollObj = db.collection(archiveAnnoColl);
    var annoType = "def";
    if ( argParser.type ) {
        annoType = argParser.type;
    }

    //// Validate VCF File, ID and also ID for Multi-Sample VCF Files ///
    try {
        var val = await parseFile(inputFile,createLog,annoCollection,archiveAnnoCollObj,annoType,assemblyType);
        createLog.debug("Check the value returned from the promise of parseFile");
        if ( ( val == "Success" ) || ( val == "Duplicate" ) ) {
            createLog.debug("Hey !! exit the process ");
            process.exit(0);
        }
    } catch(err) {
        createLog.debug("Error is "+err);
        process.exit(0);
    }

})();

async function parseFile(file,createLog,annoCollection,archiveAnnoCollObj,annoType,assemblyType) {
    var reFile = /\.gz/g;
    var rd;
    if (file.match(reFile)) {
        rd = readline.createInterface({
            input: fs.createReadStream(file).pipe(zlib.createGunzip()),
            console: false
        });
    } else {
        rd = readline.createInterface({
            input: fs.createReadStream(file),
            console: false
        });
    }

    var basePath = path.parse(__dirname).dir;
    var jsonP = path.join(basePath,'config','chrMap.json');

    var mapJson = fs.readFileSync(jsonP);
    var chrData = JSON.parse(mapJson);
    var chrMap = chrData['chromosomes'];

    var bulkOps = [];
    var verBulkOps = [];

    
    rd.on('line', function (line) {
        var document = {};
        var updateDoc = {};
        var parsedJson = JSON.parse(line);
        //console.dir(parsedJson);

        var filter = {};
        var setFilter = {};
        var updateFilter = {};

        // ver coll filter 
        var filterV = {};
        var setFilterV = {};
        var updateFilterV = {};

        var id = parsedJson['_id'];
        var arr = id.split('-');

        // Chromosome number for X and Y were replaced to numerical counterparts when novel variants were generated
        // Reason : Annotation ENgines VEP,CADD expects the chromosomes X and Y. Update them before uploading the annotations to mongo collections
        if ( arr[0] == "X" ) {
            var chr = 23;
            id = chr+'-'+arr[1]+'-'+arr[2]+'-'+arr[3];
        } else if ( arr[0] == "Y" ) {
            var chr = 24;
            id = chr+'-'+arr[1]+'-'+arr[2]+'-'+arr[3];
        } else {
            // update chromosome as part of id for non-canonical chromosomes
            //var mapChr1 = 'chr'+arr[0];
            var mapChr1 = arr[0];
            //console.log(`mapChr1 ${mapChr1}`);
            if ( chrMap[mapChr1] ) {
                var intChr = chrMap[mapChr1];
                //console.log(`intChr ${intChr}`);
                id = intChr+'-'+arr[1]+'-'+arr[2]+'-'+arr[3];
                //console.log(`id ${id}`);
            }
        }

        // Check and retrieve the data from the structures that were exported by the parser engine from mongodb
        // structure match with the existing data structure. retrieve the data and upload them to the mongo annotation collection
        if ( parsedJson['ClinVar'] ) {
            //console.log("ClinVar field present");
            setFilter['ClinVar'] = parsedJson['ClinVar'];
        }
        // check and add RNA Central annotations
        if ( parsedJson['RNACentral'] ) {
            //console.log("RNACentral field present");
            setFilter['RNACentral'] = parsedJson['RNACentral'];
        }

        if ( parsedJson['annotation'] ) {
            //console.log("annotation field present")
            // reanno request : don't update maxent annotations directly
            // reanno req : store maxent annotations in reannotation field
            // import request : update maxent annotations
            // ------- 26/08/24 commented - not relevant for archival process ---- 
            //if ((annoType != "reannotate" ) || (! parsedJson['maxent'])) {
                setFilter['annotation'] = parsedJson['annotation'];
            //} 
	        
        }

        // including additional field for the re-annotated gene annotations.
        // ------ 26/08/24 commented - not relevant for archival process
        /*if ( annoType == "reannotate" && parsedJson['annotation']) {
            //console.log("reannotate option provided");
            //console.log("including reannotation field in filter");
            setFilter['reannotation'] = parsedJson['annotation'];
        }*/

        if ( parsedJson['regulatory_feature_consequences'] ) {
            //console.log("reg feature field present")
            setFilter['regulatory_feature_consequences'] = parsedJson['regulatory_feature_consequences'];
        }

        if ( parsedJson['motif_feature_consequences'] ) {
            //console.log("motif feature present")
            setFilter['motif_feature_consequences'] = parsedJson['motif_feature_consequences'];
        }
 
        if ( parsedJson['gnomAD'] ) {
            // v4.0 gnomAD - available only for GRCh38
            if ( assemblyType == "GRCh38" ) {
                var gnomADVal = ['AC','AC_XX','AC_XY','AN','AN_XX','AN_XY','AF','AF_XX','AF_XY','AC_asj','AN_asj','AF_asj','AC_asj_XX','AC_asj_XY','AN_asj_XX','AN_asj_XY','AF_asj_XX','AF_asj_XY','AC_afr','AN_afr','AF_afr','AC_afr_XX','AC_afr_XY','AN_afr_XX','AN_afr_XY','AF_afr_XX','AF_afr_XY','AC_mid','AN_mid','AF_mid','AC_mid_XX','AC_mid_XY','AN_mid_XX','AN_mid_XY','AF_mid_XX','AF_mid_XY','AC_nfe','AN_nfe','AF_nfe','AC_nfe_XX','AC_nfe_XY','AN_nfe_XX','AN_nfe_XY','AF_nfe_XX','AF_nfe_XY','nhomalt','nhomalt_XX', 'nhomalt_XY', 'nhomalt_asj', 'nhomalt_afr','nhomalt_mid','nhomalt_nfe','nhomalt_asj_XX','nhomalt_asj_XY', 'nhomalt_afr','nhomalt_afr_XX','nhomalt_afr_XY','nhomalt_mid','nhomalt_mid_XX','nhomalt_mid_XY','nhomalt_nfe','nhomalt_nfe_XX','nhomalt_nfe_XY','grpmax','nhomalt_grpmax','AC_grpmax','AN_grpmax','AF_grpmax','AC_raw','AN_raw','AF_raw','nhomalt_raw','faf95','faf99'];

                const result = {};

                // Iterate over the keysToCheck array
                gnomADVal.forEach(key => {
                    if (parsedJson['gnomAD'].hasOwnProperty(key) && parsedJson['gnomAD'][key] !== undefined) {
                        // If the key exists and has a defined value, add it to the result object
                        result[key] = parsedJson['gnomAD'][key];
                    }
                });

                //console.log(result);
                setFilter['gnomAD'] = result;
            } else {
                // GRCh37 - old version of gnomAD
                setFilter['gnomAD'] = parsedJson['gnomAD'];
            }
            
        }

        if ( parsedJson['CADD_PhredScore'] ) {
            //console.log("CADD phred score present")
            setFilter['CADD_PhredScore'] = parsedJson['CADD_PhredScore'];
        }

        var annoCriteria = 1;
        // versioned annotations are turned from 1 to 0
        var verAnnoCriteria = 0;
        // transcript maxent process required only for reannotation request
        // not needed for novel variants.
        if ( parsedJson['maxent'] ) {
            setFilter['maxent'] = parsedJson['maxent'];
            /*if ( annoType == "reannotate" ) {
                annoCriteria = 2;
                // including another criteria to copy transcripts with maxent('reannotate') to 'annotation'  
            }*/
        }

        if ( parsedJson['encode']) {
            setFilter['encode'] = parsedJson['encode'];
        }
        
        //setFilter['annotated'] = 1;
        setFilter['annotated'] = annoCriteria;
        filter['filter'] = {'_id' : id};
        filter['update'] = {$set : setFilter};

        // only the annotated field is updated for annotation version collections. field value updated from 1 to 0.
        setFilterV['annotated'] = verAnnoCriteria;
        filterV['filter'] = {'_id' : id};
        filterV['update'] = {$set : setFilterV};

        updateFilter['updateOne'] = filter;
        // by default upsert is false. Setting it to true below
        updateFilter['updateOne']['upsert'] = 1;

        // versioning update filter
        // upsert is not set for versioning collection. added 9/9/2024
        updateFilterV['updateOne'] = filterV;
        updateFilterV['updateOne']['upsert'] = 1;
        
        
        bulkOps.push(updateFilter);
        verBulkOps.push(updateFilterV);

        if ( bulkOps.length  === 1000 ) {
            createLog.debug("Execute the bulk update ");
            //console.dir(bulkOps,{"depth":null});
            annoCollection.bulkWrite(bulkOps, { 'ordered': false }).then(function (res) {
                createLog.debug(res.insertedCount, res.modifiedCount, res.deletedCount);
            }).catch((err1) => {
                createLog.debug("Error executing the bulk operations");
                createLog.debug(err1);
            });
            createLog.debug("Initializing bulkOps to 0");
            bulkOps = [];
        }

        if ( verBulkOps.length  === 1000 ) {
            createLog.debug("Execute the bulk update ");
            //console.dir(bulkOps,{"depth":null});
            archiveAnnoCollObj.bulkWrite(verBulkOps, { 'ordered': false }).then(function (res) {
                createLog.debug(res.insertedCount, res.modifiedCount, res.deletedCount);
            }).catch((err1) => {
                createLog.debug("Error executing the bulk operations");
                createLog.debug(err1);
            });
            createLog.debug("Initializing bulkOps to 0");
            verBulkOps = [];
        }

    });

    return new Promise( resolve => {
        rd.on('close', async () => {
            if ( bulkOps.length > 0 || verBulkOps.length > 0 ) {
                try {
                    var res1 = await annoCollection.bulkWrite(bulkOps,{'ordered':false});
                    var res1 = await archiveAnnoCollObj.bulkWrite(verBulkOps,{'ordered':false});
                    resolve("Success");
                } catch(err1) {
                    // duplicate key issue when the key is present in the existing mongo collection
                    //var res1 = await verannoCollection.bulkWrite(verBulkOps,{'ordered':false});
                    resolve("Duplicate");
                }
            } else {
                // This condition is required to handle the case when the size of bulkOps data was loaded in the previous modulus 
                // When there is not enough data to be loaded to mongo db, we have to resolve the promise to ensure that it is resolved at the calling await
                // exit condition of the process is performed on the resolved promise
                resolve("Success");
            }
        });
    });

    rd.on('end', function () {
        createLog.debug("END event call received");
    });

    rd.on('error', function () {
        createLog.debug("ERROR event call received.Filehandle destroyed. Internal!!");
    });
}

function applyFont(txt) {
    return colors.red(txt); //display the help text in red on the console
}


